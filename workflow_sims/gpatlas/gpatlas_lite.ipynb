{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import pickle as pk\n",
    "import sys\n",
    "import time as tm\n",
    "import argparse\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from captum.attr import FeatureAblation\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from typing import Iterator, Optional\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import cast\n",
    "import h5py\n",
    "import pickle\n",
    "\n",
    "\n",
    "sns.set_theme()\n",
    "\n",
    "batch_size = 50\n",
    "num_workers = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_latent_space = 300\n",
    "num_epochs = 1\n",
    "n_phen = 25\n",
    "\n",
    "############\n",
    "\n",
    "n_geno = 100000\n",
    "n_alleles = 2\n",
    "latent_space_g = 1000\n",
    "num_epochs_gen = 1\n",
    "\n",
    "############\n",
    "\n",
    "gp_latent_space = p_latent_space\n",
    "epochs_gen_phen = 2\n",
    "\n",
    "l1_lambda = 0.00000000000001\n",
    "l2_lambda = 0.00000000000001\n",
    "\n",
    "#l1_lambda = 0.08\n",
    "#l2_lambda = 0.08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_hdf5(data_input: dict, hdf5_path: Path, gzip: bool = True) -> Path:\n",
    "    data = data_input\n",
    "    str_dt = h5py.string_dtype(encoding=\"utf-8\")\n",
    "\n",
    "    with h5py.File(hdf5_path, \"w\") as h5f:\n",
    "        metadata_group = h5f.create_group(\"metadata\")\n",
    "\n",
    "        loci_array = np.array(data[\"loci\"], dtype=str_dt)\n",
    "        metadata_group.create_dataset(\"loci\", data=loci_array)\n",
    "\n",
    "        pheno_names_array = np.array(data[\"phenotype_names\"], dtype=str_dt)\n",
    "        metadata_group.create_dataset(\"phenotype_names\", data=pheno_names_array)\n",
    "\n",
    "        strains_group = h5f.create_group(\"strains\")\n",
    "\n",
    "        for idx, strain_id in enumerate(data[\"strain_names\"]):\n",
    "            strain_grp = strains_group.create_group(strain_id)\n",
    "\n",
    "            pheno = np.array(data[\"phenotypes\"][idx], dtype=np.float64)\n",
    "            strain_grp.create_dataset(\"phenotype\", data=pheno)\n",
    "\n",
    "            genotype = np.array(data[\"genotypes\"][idx], dtype=np.int8)\n",
    "            strain_grp.create_dataset(\n",
    "                \"genotype\",\n",
    "                data=genotype,\n",
    "                chunks=True,\n",
    "                compression=\"gzip\" if gzip else None,\n",
    "            )\n",
    "\n",
    "        print(f\"{hdf5_path} generated from {data_input}.\")\n",
    "\n",
    "    return hdf5_path\n",
    "out_dict={}\n",
    "\n",
    "phen_file = open(\"../alphasimr_output/test_sim_WF_1kbt_10000n_5000000bp_p.txt\" , 'r')\n",
    "\n",
    "phens = phen_file.read().split('\\n')\n",
    "phens = [x.split() for x in phens]\n",
    "\n",
    "out_dict['phenotype_names'] = phens[0][1:] #extract header of pheno names from first row\n",
    "#dict(list(out_dict.items())[2:3])\n",
    "\n",
    "\n",
    "out_dict['strain_names'] = [x[0] for x in phens[1:-1]] #strain names extracted from first colun skipping one row\n",
    "out_dict['phenotypes'] = [x[1:] for x in phens[1:-1]]\n",
    "out_dict['phenotypes'] = [[float(y)  if y!= 'NA' else 0 for y in x[1:]] for x in phens[1:-1]] #convert pheno to float, dealing with NA\n",
    "\n",
    "\n",
    "\n",
    "genotype_file = open(\"../alphasimr_output/test_sim_WF_1kbt_10000n_5000000bp_g.txt\" , 'r')\n",
    "\n",
    "gens = genotype_file.read().split('\\n')\n",
    "gens = [x.split() for x in gens]\n",
    "\n",
    "out_dict['loci'] = [x[0] for x in gens[1:-1]]\n",
    "new_coding_dict = {'0':[1,0],'1':[0,1]}\n",
    "out_dict['genotypes'] = [[new_coding_dict[x] for x in [gens[y][n] for y in range(len(gens))[1:-1]]] for n in range(len(gens[0]))[1:]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "in_data = out_dict\n",
    "\n",
    "out_dict_test = {}\n",
    "out_dict_train = {}\n",
    "\n",
    "categories_to_stratefy = ['phenotypes', 'genotypes', 'strain_names']\n",
    "categories_to_copy = [x for x in in_data.keys() if x not in categories_to_stratefy]\n",
    "\n",
    "train_length = round(len(in_data['strain_names'])*0.85)\n",
    "\n",
    "#train set\n",
    "for x in categories_to_copy:\n",
    " out_dict_train[x] = in_data[x]\n",
    "\n",
    "for x in categories_to_stratefy:\n",
    " out_dict_train[x] = in_data[x][:train_length]\n",
    "\n",
    "save_to_hdf5(out_dict_train, \"TESTEST.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#test set\n",
    "for x in categories_to_copy:\n",
    " out_dict_test[x] = in_data[x]\n",
    "\n",
    "for x in categories_to_stratefy:\n",
    " out_dict_test[x] = in_data[x][train_length:]\n",
    "\n",
    "#pk.dump(out_dict_test, open('gpatlas/' + file_prefix + '_test.pk','wb'))\n",
    "save_to_hdf5(out_dict_test, snakemake.output['test_data_input'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pickle_to_hdf5(pickle_path: Path, hdf5_path: Path, gzip: bool = True) -> Path:\n",
    "    data = pickle.load(open(pickle_path, \"rb\"))\n",
    "    str_dt = h5py.string_dtype(encoding=\"utf-8\")\n",
    "\n",
    "    with h5py.File(hdf5_path, \"w\") as h5f:\n",
    "        metadata_group = h5f.create_group(\"metadata\")\n",
    "\n",
    "        loci_array = np.array(data[\"loci\"], dtype=str_dt)\n",
    "        metadata_group.create_dataset(\"loci\", data=loci_array)\n",
    "\n",
    "        pheno_names_array = np.array(data[\"phenotype_names\"], dtype=str_dt)\n",
    "        metadata_group.create_dataset(\"phenotype_names\", data=pheno_names_array)\n",
    "\n",
    "        strains_group = h5f.create_group(\"strains\")\n",
    "\n",
    "        for idx, strain_id in enumerate(data[\"strain_names\"]):\n",
    "            strain_grp = strains_group.create_group(strain_id)\n",
    "\n",
    "            pheno = np.array(data[\"phenotypes\"][idx], dtype=np.float64)\n",
    "            strain_grp.create_dataset(\"phenotype\", data=pheno)\n",
    "\n",
    "            genotype = np.array(data[\"genotypes\"][idx], dtype=np.int8)\n",
    "            strain_grp.create_dataset(\n",
    "                \"genotype\",\n",
    "                data=genotype,\n",
    "                chunks=True,\n",
    "                compression=\"gzip\" if gzip else None,\n",
    "            )\n",
    "\n",
    "        print(f\"{hdf5_path} generated from {pickle_path}.\")\n",
    "\n",
    "    return hdf5_path\n",
    "\n",
    "class BaseDataset(Dataset):\n",
    "    def __init__(self, hdf5_path: Path) -> None:\n",
    "        self.h5 = h5py.File(hdf5_path, \"r\")\n",
    "\n",
    "        self._strain_group = cast(h5py.Group, self.h5[\"strains\"])\n",
    "        self.strains: list[str] = list(self._strain_group.keys())\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self._strain_group)\n",
    "\n",
    "\n",
    "class GenoPhenoDataset(BaseDataset):\n",
    "    def __getitem__(self, idx: int) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        strain = self.strains[idx]\n",
    "\n",
    "        strain_data = cast(Dataset, self._strain_group[strain])\n",
    "\n",
    "        # Note: genotype is being cast as float32 here, reasons not well understood.\n",
    "        phens = torch.tensor(strain_data[\"phenotype\"][:], dtype=torch.float32)\n",
    "        gens = torch.tensor(strain_data[\"genotype\"][:], dtype=torch.float32).flatten()\n",
    "\n",
    "        return phens, gens\n",
    "\n",
    "class PhenoDataset(BaseDataset):\n",
    "    def __getitem__(self, idx: int):\n",
    "        strain = self.strains[idx]\n",
    "\n",
    "        strain_data = cast(Dataset, self._strain_group[strain])\n",
    "\n",
    "        # Note: genotype is being cast as float32 here, reasons not well understood.\n",
    "        phens = torch.tensor(strain_data[\"phenotype\"][:], dtype=torch.float32)\n",
    "\n",
    "\n",
    "        return phens\n",
    "###########\n",
    "class GenoDataset(BaseDataset):\n",
    "    def __getitem__(self, idx: int) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        strain = self.strains[idx]\n",
    "\n",
    "        strain_data = cast(Dataset, self._strain_group[strain])\n",
    "\n",
    "        # Note: genotype is being cast as float32 here, reasons not well understood.\n",
    "        gens = torch.tensor(strain_data[\"genotype\"][:], dtype=torch.float32).flatten()\n",
    "\n",
    "        return  gens\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "#    parser = argparse.ArgumentParser(description=\"Convert a Dave's pickle data to an HDF5 file.\")\n",
    "#    parser.add_argument(\"pickle_path\", type=Path, help=\"Path to the input pickle file.\")\n",
    "#    parser.add_argument(\"hdf5_path\", type=Path, help=\"Path to the output HDF5 file.\")\n",
    "#    parser.add_argument(\"gzip\", type=bool, help=\"Gzip datasets (decreases read speed).\")\n",
    "#    args = parser.parse_args()\n",
    "\n",
    "    #convert_pickle_to_hdf5(args.pickle_path, args.hdf5_path, args.gzip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert_pickle_to_hdf5('gpatlas/test_sim_WF_1kbt_10000n_5000000bp_test.pk', 'gpatlas/test_sim_WF_1kbt_10000n_5000000bp_test.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_pheno = PhenoDataset('gpatlas/test_sim_WF_1kbt_10000n_5000000bp_train.hdf5')\n",
    "test_data_pheno = PhenoDataset('gpatlas/test_sim_WF_1kbt_10000n_5000000bp_test.hdf5')\n",
    "\n",
    "train_data_geno = GenoDataset('gpatlas/test_sim_WF_1kbt_10000n_5000000bp_train.hdf5')\n",
    "test_data_geno = GenoDataset('gpatlas/test_sim_WF_1kbt_10000n_5000000bp_test.hdf5')\n",
    "\n",
    "train_data_gp = GenoPhenoDataset('gpatlas/test_sim_WF_1kbt_10000n_5000000bp_train.hdf5')\n",
    "test_data_gp = GenoPhenoDataset('gpatlas/test_sim_WF_1kbt_10000n_5000000bp_test.hdf5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader_pheno = torch.utils.data.DataLoader(\n",
    "    dataset=train_data_pheno, batch_size=batch_size, num_workers=num_workers, shuffle=True\n",
    ")\n",
    "test_loader_pheno = torch.utils.data.DataLoader(\n",
    "    dataset=test_data_pheno, batch_size=batch_size, num_workers=num_workers, shuffle=True\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "train_loader_geno = torch.utils.data.DataLoader(\n",
    "    dataset=train_data_geno, batch_size=batch_size, num_workers=num_workers, shuffle=True\n",
    ")\n",
    "test_loader_geno = torch.utils.data.DataLoader(\n",
    "    dataset=test_data_geno, batch_size=batch_size, num_workers=num_workers, shuffle=True\n",
    ")\n",
    "\n",
    "\n",
    "train_loader_gp = torch.utils.data.DataLoader(\n",
    "    dataset=train_data_gp, batch_size=batch_size, num_workers=num_workers, shuffle=True\n",
    ")\n",
    "test_loader_gp = torch.utils.data.DataLoader(\n",
    "    dataset=test_data_gp, batch_size=batch_size, num_workers=num_workers, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# encoder\n",
    "class Q_net(nn.Module):\n",
    "    def __init__(self, phen_dim=None, N=None):\n",
    "        super().__init__()\n",
    "        if N is None:\n",
    "            N = p_latent_space\n",
    "        if phen_dim is None:\n",
    "            phen_dim = n_phen\n",
    "\n",
    "        batchnorm_momentum = 0.8\n",
    "        latent_dim = p_latent_space\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(in_features=phen_dim, out_features=N),\n",
    "            nn.BatchNorm1d(N, momentum=batchnorm_momentum),\n",
    "            nn.LeakyReLU(0.01, inplace=True),\n",
    "            nn.Linear(in_features=N, out_features=latent_dim),\n",
    "            nn.BatchNorm1d(latent_dim, momentum=batchnorm_momentum),\n",
    "            nn.LeakyReLU(0.01, inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# decoder\n",
    "class P_net(nn.Module):\n",
    "    def __init__(self, phen_dim=None, N=None):\n",
    "        if N is None:\n",
    "            N = p_latent_space\n",
    "        if phen_dim is None:\n",
    "            phen_dim = n_phen\n",
    "\n",
    "        out_phen_dim = n_phen\n",
    "        #vabs.n_locs * vabs.n_alleles\n",
    "        latent_dim = p_latent_space\n",
    "\n",
    "        batchnorm_momentum = 0.8\n",
    "\n",
    "        super().__init__()\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(in_features=latent_dim, out_features=N),\n",
    "            nn.BatchNorm1d(N, momentum=batchnorm_momentum),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Linear(in_features=N, out_features=out_phen_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.decoder(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# set minimum variable\n",
    "EPS = 1e-15\n",
    "reg_lr = 0.001\n",
    "adam_b = (0.5, 0.999)\n",
    "\n",
    "\n",
    "# initialize all networks\n",
    "Q = Q_net()\n",
    "P = P_net()\n",
    "\n",
    "Q.to(device)\n",
    "P.to(device)\n",
    "\n",
    "optim_P = torch.optim.Adam(P.parameters(), lr=reg_lr, betas=adam_b)\n",
    "optim_Q_enc = torch.optim.Adam(Q.parameters(), lr=reg_lr, betas=adam_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train phen autoencoder\n",
    "n_phens = n_phen\n",
    "n_phens_pred = n_phen\n",
    "rcon_loss = []\n",
    "\n",
    "start_time = tm.time()\n",
    "\n",
    "for n in range(num_epochs):\n",
    "    for i, (phens) in enumerate(train_loader_pheno):\n",
    "        phens = phens[:, :n_phens]\n",
    "        phens = phens.to(device)  # move data to GPU if it is there\n",
    "        batch_size = phens.shape[0]  # redefine batch size here to allow for incomplete batches\n",
    "\n",
    "        # reconstruction loss\n",
    "        Q.zero_grad()\n",
    "        P.zero_grad()\n",
    "\n",
    "        noise_phens = phens + (0.001**0.5) * torch.randn(phens.shape).to(device)\n",
    "\n",
    "        z_sample = Q(noise_phens)\n",
    "        X_sample = P(z_sample)\n",
    "\n",
    "        # recon_loss = F.mse_loss(X_sample+EPS,phens[:,:n_phens_pred]+EPS)\n",
    "\n",
    "        recon_loss = F.l1_loss(X_sample + EPS, phens[:, :n_phens_pred] + EPS)\n",
    "\n",
    "        l1_reg = torch.linalg.norm(torch.sum(Q.encoder[0].weight, axis=0), 1)\n",
    "        l2_reg = torch.linalg.norm(torch.sum(Q.encoder[0].weight, axis=0), 2)\n",
    "\n",
    "        recon_loss = recon_loss + l1_reg * 0.0000000001 + l2_reg * 0.000000001\n",
    "\n",
    "\n",
    "        rcon_loss.append(float(recon_loss.detach()))\n",
    "\n",
    "        recon_loss.backward()\n",
    "        optim_Q_enc.step()\n",
    "        optim_P.step()\n",
    "\n",
    "    cur_time = tm.time() - start_time\n",
    "    start_time = tm.time()\n",
    "    print(\n",
    "        \"Epoch num: \"\n",
    "        + str(n)\n",
    "        + \" batchno \"\n",
    "        + str(i)\n",
    "        + \" r_con_loss: \"\n",
    "        + str(rcon_loss[-1])\n",
    "        + \" epoch duration: \"\n",
    "        + str(cur_time)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(rcon_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gencoder\n",
    "class GQ_net(nn.Module):\n",
    "    def __init__(self, n_loci=None, N=None):\n",
    "        super().__init__()\n",
    "        if N is None:\n",
    "            N = latent_space_g\n",
    "        if n_loci is None:\n",
    "            n_loci = n_geno * n_alleles\n",
    "\n",
    "        batchnorm_momentum = 0.8\n",
    "        g_latent_dim = latent_space_g\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(in_features=n_loci, out_features=N),\n",
    "            nn.BatchNorm1d(N, momentum=0.8),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Linear(in_features=N, out_features=g_latent_dim),\n",
    "            nn.BatchNorm1d(g_latent_dim, momentum=0.8),\n",
    "            nn.LeakyReLU(0.01),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# gendecoder\n",
    "class GP_net(nn.Module):\n",
    "    def __init__(self, n_loci=None, N=None):\n",
    "        super().__init__()\n",
    "        if N is None:\n",
    "            N = latent_space_g\n",
    "        if n_loci is None:\n",
    "            n_loci = n_geno * n_alleles\n",
    "\n",
    "        batchnorm_momentum = 0.8\n",
    "        g_latent_dim = latent_space_g\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(in_features=g_latent_dim, out_features=N),\n",
    "            nn.BatchNorm1d(N, momentum=batchnorm_momentum),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Linear(in_features=N, out_features=n_loci),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GQ = GQ_net()\n",
    "GP = GP_net()\n",
    "\n",
    "GQ.to(device)\n",
    "GP.to(device)\n",
    "\n",
    "EPS = 1e-15\n",
    "reg_lr = 0.001\n",
    "adam_b = (0.5, 0.999)\n",
    "\n",
    "optim_GQ_enc = torch.optim.Adam(GQ.parameters(), lr=reg_lr, betas=adam_b)\n",
    "optim_GP_dec = torch.optim.Adam(GP.parameters(), lr=reg_lr, betas=adam_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train genotype autoencoder\n",
    "g_rcon_loss = []\n",
    "start_time = tm.time()\n",
    "gen_noise = 1 - 0.3\n",
    "\n",
    "for n in range(num_epochs_gen):\n",
    "    for i, batch in enumerate(train_loader_geno):\n",
    "        # Print every 10 batches\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Processing batch {i} in epoch {n}\")\n",
    "\n",
    "        gens = batch\n",
    "        # Flatten the genotypes properly\n",
    "        gens = gens.reshape(gens.shape[0], -1)  # This will give shape [50, 200000]\n",
    "        gens = gens.to(device)\n",
    "        batch_size = gens.shape[0]\n",
    "\n",
    "        # Clear gradients\n",
    "        GP.zero_grad()\n",
    "        GQ.zero_grad()\n",
    "\n",
    "        # Add noise to input\n",
    "        pos_noise = np.random.binomial(1, gen_noise/2, gens.shape)\n",
    "        neg_noise = np.random.binomial(1, gen_noise/2, gens.shape)\n",
    "        noise_gens = torch.tensor(\n",
    "            np.where((gens.cpu() + pos_noise - neg_noise) > 0, 1, 0),\n",
    "            dtype=torch.float32\n",
    "        ).to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        z_sample = GQ(noise_gens)\n",
    "        X_sample = GP(z_sample)\n",
    "\n",
    "        # Calculate loss\n",
    "        g_recon_loss = F.binary_cross_entropy(X_sample + EPS, gens + EPS)\n",
    "\n",
    "        # Add regularization if desired\n",
    "        l1_reg = torch.linalg.norm(torch.sum(GQ.encoder[0].weight, axis=0), 1)\n",
    "        l2_reg = torch.linalg.norm(torch.sum(GQ.encoder[0].weight, axis=0), 2)\n",
    "        g_recon_loss = g_recon_loss + l1_reg * l1_lambda + l2_reg * l2_lambda\n",
    "\n",
    "        # Record loss\n",
    "        g_rcon_loss.append(float(g_recon_loss.detach()))\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        g_recon_loss.backward()\n",
    "        optim_GQ_enc.step()\n",
    "        optim_GP_dec.step()\n",
    "\n",
    "    # Print epoch summary\n",
    "    cur_time = tm.time() - start_time\n",
    "    start_time = tm.time()\n",
    "    print(\n",
    "        f\"Epoch num: {n}, batchno: {i}, g_recon_loss: {g_rcon_loss[-1]:.6f}, epoch duration: {cur_time:.2f}s\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(g_rcon_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GQ_to_P_net(nn.Module):\n",
    "    def __init__(self, N=None):\n",
    "        super().__init__()\n",
    "        if N is None:\n",
    "            N = gp_latent_space\n",
    "\n",
    "        batchnorm_momentum = 0.8\n",
    "        g_latent_dim = latent_space_g\n",
    "        latent_dim = p_latent_space\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(in_features=g_latent_dim, out_features=N),\n",
    "            nn.BatchNorm1d(N, momentum=batchnorm_momentum),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Linear(in_features=N, out_features=latent_dim),\n",
    "            nn.BatchNorm1d(N, momentum=batchnorm_momentum),\n",
    "            nn.LeakyReLU(0.01),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GQP = GQ_to_P_net()\n",
    "GQP.to(device)\n",
    "optim_GQP_dec = torch.optim.Adam(GQP.parameters(), lr=reg_lr, betas=adam_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train genotype to phenotype network\n",
    "\n",
    "# Freeze weights in P (phenotype decoder) and GQ (genetic encoder)\n",
    "P.requires_grad_(False)\n",
    "P.eval()\n",
    "GQ.requires_grad_(False)\n",
    "GQ.eval()\n",
    "\n",
    "num_epochs_gen_phen = epochs_gen_phen\n",
    "gen_noise = 1 - 0.3\n",
    "g_p_rcon_loss = []\n",
    "start_time = tm.time()\n",
    "\n",
    "for n in range(num_epochs_gen_phen):\n",
    "    for i, (phens, gens) in enumerate(train_loader_gp):\n",
    "        # Print progress every 10 batches\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Processing batch {i} in epoch {n}\")\n",
    "\n",
    "        # Move phenotype data to device\n",
    "        phens = phens.to(device)\n",
    "\n",
    "        # Move and prepare genotype data\n",
    "        #gens = gens.reshape(gens.shape[0], -1)  # Flatten genotypes\n",
    "        gens = gens.to(device)\n",
    "        batch_size = phens.shape[0]\n",
    "\n",
    "        # Generate noise on GPU if available\n",
    "        if device.type == 'cuda':\n",
    "            noise_gens = torch.bernoulli(torch.full_like(gens, gen_noise/2))\n",
    "            neg_noise = torch.bernoulli(torch.full_like(gens, gen_noise/2))\n",
    "            noise_gens = torch.clamp(gens + noise_gens - neg_noise, 0, 1)\n",
    "        else:\n",
    "            # Generate noise on CPU\n",
    "            pos_noise = np.random.binomial(1, gen_noise/2, gens.shape)\n",
    "            neg_noise = np.random.binomial(1, gen_noise/2, gens.shape)\n",
    "            noise_gens = torch.tensor(\n",
    "                np.where((gens.cpu() + pos_noise - neg_noise) > 0, 1, 0),\n",
    "                dtype=torch.float32\n",
    "            ).to(device)\n",
    "\n",
    "        # Clear gradients\n",
    "        P.zero_grad()\n",
    "        GQP.zero_grad()\n",
    "        GQ.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        z_sample = GQ(noise_gens)\n",
    "        z_sample = GQP(z_sample)\n",
    "        X_sample = P(z_sample)\n",
    "\n",
    "        # Calculate loss\n",
    "        g_p_recon_loss = F.l1_loss(X_sample + EPS, phens[:, :n_phens_pred] + EPS)\n",
    "\n",
    "        # Add regularization\n",
    "        l1_reg = torch.linalg.norm(torch.sum(GQP.encoder[0].weight, axis=0), 1)\n",
    "        l2_reg = torch.linalg.norm(torch.sum(GQP.encoder[0].weight, axis=0), 2)\n",
    "        g_p_recon_loss = g_p_recon_loss + l1_reg * l1_lambda + l2_reg * l2_lambda\n",
    "\n",
    "        # Record loss\n",
    "        g_p_rcon_loss.append(float(g_p_recon_loss.detach()))\n",
    "\n",
    "        # Backward pass\n",
    "        g_p_recon_loss.backward()\n",
    "\n",
    "        # Optimization step\n",
    "        optim_P.step()\n",
    "        optim_GQ_enc.step()\n",
    "        optim_GQP_dec.step()\n",
    "\n",
    "        # Clean up to free memory\n",
    "        del z_sample, X_sample, noise_gens\n",
    "        if device.type == 'cuda':\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    # Print epoch summary\n",
    "    cur_time = tm.time() - start_time\n",
    "    start_time = tm.time()\n",
    "    print(\n",
    "        f\"Epoch num: {n}, batchno: {i}, r_con_loss: {g_p_rcon_loss[-1]:.6f}, epoch duration: {cur_time:.2f}s\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(g_p_rcon_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phen_encodings = []\n",
    "phens = []\n",
    "phen_latent = []\n",
    "\n",
    "# Set models to eval mode\n",
    "GQ.eval()\n",
    "GQP.eval()\n",
    "P.eval()\n",
    "\n",
    "with torch.no_grad():  # Disable gradient computation for inference\n",
    "    for ph, gt in test_loader_gp:  # Using combined loader\n",
    "        # Move data to device\n",
    "        ph = ph.to(device)\n",
    "        gt = gt.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        z_sample = GQ(gt)\n",
    "        z_sample = GQP(z_sample)\n",
    "        X_sample = P(z_sample)\n",
    "\n",
    "        # Store results\n",
    "        phens.append(ph.cpu().numpy())\n",
    "        phen_encodings.append(X_sample.cpu().numpy())\n",
    "        phen_latent.append(z_sample.cpu().numpy())\n",
    "\n",
    "        # Clean up memory\n",
    "        del z_sample, X_sample\n",
    "        if device.type == 'cuda':\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "# Concatenate all batches and transpose\n",
    "phens = np.concatenate(phens, axis=0).T\n",
    "phen_encodings = np.concatenate(phen_encodings, axis=0).T\n",
    "phen_latent = np.concatenate(phen_latent, axis=0).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(len(phens[:n_phens_pred])):\n",
    "    plt.plot(phens[n], phen_encodings[n], \"o\")\n",
    "plt.xlabel(\"real\")\n",
    "plt.ylabel(\"predicted\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([sc.stats.pearsonr(phens[n], phen_encodings[n])[0] for n in range(len(phens[:n_phens_pred]))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phen_encodings = []\n",
    "phens = []\n",
    "phen_latent = []\n",
    "\n",
    "\n",
    "# Set models to eval mode\n",
    "Q.eval()\n",
    "P.eval()\n",
    "\n",
    "with torch.no_grad():  # Disable gradient computation for inference\n",
    "    for ph in test_loader_pheno:\n",
    "        # Move data to device\n",
    "        ph = ph.to(device)\n",
    "\n",
    "        # Forward pass through autoencoder\n",
    "        z_sample = Q(ph)  # Encode\n",
    "        X_sample = P(z_sample)  # Decode\n",
    "\n",
    "        # Store results\n",
    "        phens.append(ph.cpu().numpy())\n",
    "        phen_encodings.append(X_sample.cpu().numpy())\n",
    "        phen_latent.append(z_sample.cpu().numpy())\n",
    "\n",
    "        # Clean up memory\n",
    "        del z_sample, X_sample\n",
    "        if device.type == 'cuda':\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "# Concatenate all batches and transpose\n",
    "phens = np.concatenate(phens, axis=0).T\n",
    "phen_encodings = np.concatenate(phen_encodings, axis=0).T\n",
    "phen_latent = np.concatenate(phen_latent, axis=0).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(len(phens[:n_phens_pred])):\n",
    "    plt.plot(phens[n], phen_encodings[n], \"o\")\n",
    "plt.xlabel(\"real\")\n",
    "plt.ylabel(\"predicted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geno_encodings = []\n",
    "genos = []\n",
    "geno_latent = []\n",
    "\n",
    "# Set models to eval mode\n",
    "GQ.eval()\n",
    "GP.eval()\n",
    "\n",
    "with torch.no_grad():  # Disable gradient computation for inference\n",
    "    for gt in test_loader_geno:\n",
    "        # Move data to device\n",
    "        gt = gt.to(device)\n",
    "\n",
    "        # Forward pass through autoencoder\n",
    "        z_sample = GQ(gt)  # Encode\n",
    "        X_sample = GP(z_sample)  # Decode\n",
    "\n",
    "        # Store results\n",
    "        genos.append(gt.cpu().numpy())\n",
    "        geno_encodings.append(X_sample.cpu().numpy())\n",
    "        geno_latent.append(z_sample.cpu().numpy())\n",
    "\n",
    "        # Clean up memory\n",
    "        del z_sample, X_sample\n",
    "        if device.type == 'cuda':\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "# Concatenate all batches and transpose\n",
    "genos = np.concatenate(genos, axis=0).T\n",
    "geno_encodings = np.concatenate(geno_encodings, axis=0).T\n",
    "geno_latent = np.concatenate(geno_latent, axis=0).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f1_scores = []\n",
    "\n",
    "# Set models to eval mode\n",
    "GQ.eval()\n",
    "GP.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for gt in test_loader_geno:\n",
    "        gt = gt.to(device)\n",
    "\n",
    "        # Forward pass through autoencoder\n",
    "        z_sample = GQ(gt)\n",
    "        X_sample = GP(z_sample)\n",
    "\n",
    "        # Move to CPU and convert to numpy\n",
    "        original = gt.cpu().numpy()\n",
    "        reconstructed = X_sample.cpu().numpy()\n",
    "\n",
    "        # Reshape to [batch_size, n_loci, 2] to separate alleles\n",
    "        original = original.reshape(-1, n_geno, 2)\n",
    "        reconstructed = reconstructed.reshape(-1, n_geno, 2)\n",
    "\n",
    "        # Take just the first allele state for each locus\n",
    "        original_allele1 = original[:, :, 0]\n",
    "        reconstructed_allele1 = (reconstructed[:, :, 0] > 0.5).astype(int)\n",
    "\n",
    "        # Calculate F1 score for each sample in the batch\n",
    "        for orig, recon in zip(original_allele1, reconstructed_allele1):\n",
    "            f1 = f1_score(orig, recon, average='macro')\n",
    "            f1_scores.append(f1)\n",
    "\n",
    "# Plot distribution of F1 scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(f1_scores, bins=50)\n",
    "plt.xlabel('F1 Score')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of F1 Scores for First Allele State Reconstruction')\n",
    "plt.axvline(np.mean(f1_scores), color='r', linestyle='dashed', label=f'Mean F1: {np.mean(f1_scores):.3f}')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Average F1 Score: {np.mean(f1_scores):.3f} ± {np.std(f1_scores):.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpatlas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
