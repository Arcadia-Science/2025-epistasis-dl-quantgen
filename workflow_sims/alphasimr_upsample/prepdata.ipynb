{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pickle as pk\n",
    "import h5py\n",
    "\n",
    "\n",
    "######################################################################################\n",
    "######################################################################################\n",
    "\n",
    "def save_to_hdf5(data_input: dict, hdf5_path: Path, gzip: bool = True) -> Path:\n",
    "    data = data_input\n",
    "    str_dt = h5py.string_dtype(encoding=\"utf-8\")\n",
    "\n",
    "    with h5py.File(hdf5_path, \"w\") as h5f:\n",
    "        metadata_group = h5f.create_group(\"metadata\")\n",
    "\n",
    "        loci_array = np.array(data[\"loci\"], dtype=str_dt)\n",
    "        metadata_group.create_dataset(\"loci\", data=loci_array)\n",
    "\n",
    "        pheno_names_array = np.array(data[\"phenotype_names\"], dtype=str_dt)\n",
    "        metadata_group.create_dataset(\"phenotype_names\", data=pheno_names_array)\n",
    "\n",
    "        strains_group = h5f.create_group(\"strains\")\n",
    "\n",
    "        for idx, strain_id in enumerate(data[\"strain_names\"]):\n",
    "            strain_grp = strains_group.create_group(strain_id)\n",
    "\n",
    "            pheno = np.array(data[\"phenotypes\"][idx], dtype=np.float64)\n",
    "            strain_grp.create_dataset(\"phenotype\", data=pheno)\n",
    "\n",
    "            genotype = np.array(data[\"genotypes\"][idx], dtype=np.int8)\n",
    "            strain_grp.create_dataset(\n",
    "                \"genotype\",\n",
    "                data=genotype,\n",
    "                chunks=True,\n",
    "                compression=\"gzip\" if gzip else None,\n",
    "            )\n",
    "\n",
    "        print(f\"{hdf5_path} generated from {data_input}.\")\n",
    "\n",
    "    return hdf5_path\n",
    "out_dict={}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "######################################################################################\n",
    "######################################################################################\n",
    "# Read phenotype file\n",
    "phen_file = open('test_sim_WF_1kbt_100kups_5mb_p.txt', 'r')\n",
    "phens = phen_file.read().split('\\n')\n",
    "phens = [x.split() for x in phens if x]  # Skip empty lines\n",
    "\n",
    "# Extract phenotype information\n",
    "out_dict = {}\n",
    "out_dict['phenotype_names'] = phens[0][1:]  # Extract header of pheno names from first row\n",
    "out_dict['strain_names'] = [x[0] for x in phens[1:] if x]  # Strain names from first column\n",
    "out_dict['phenotypes'] = []\n",
    "\n",
    "# Convert phenotypes to float, handling NA values\n",
    "for x in phens[1:]:\n",
    "    if not x:  # Skip empty lines\n",
    "        continue\n",
    "    row_phenos = []\n",
    "    for y in x[1:]:\n",
    "        if y == 'NA':\n",
    "            row_phenos.append(0)  # Or use None/np.nan if preferred\n",
    "        else:\n",
    "            row_phenos.append(float(y))\n",
    "    out_dict['phenotypes'].append(row_phenos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out_dict['phenotypes'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "# Read genotype file - CSV format with headers\n",
    "genotype_file = open('test_sim_WF_1kbt_100kups_5mb_g.txt', 'r')\n",
    "gens = genotype_file.read().split('\\n')\n",
    "gens = [x.split(',') for x in gens if x]  # Split by comma\n",
    "\n",
    "# Extract locus names - first row contains locus names directly (no empty cell for sample column)\n",
    "out_dict['loci'] = gens[0]  # The entire first row contains locus names\n",
    "\n",
    "# Process genotypes - CSV format with row names but no column name for sample IDs\n",
    "new_coding_dict = {'0': [1, 0], '1': [0, 1]}\n",
    "out_dict['genotypes'] = []\n",
    "\n",
    "# For each individual row (starting from row 1 to skip header)\n",
    "for row in gens[1:]:\n",
    "    if not row or len(row) <= 1:  # Skip empty lines or incomplete rows\n",
    "        continue\n",
    "\n",
    "    # Process all genotypes for this individual (skip first column which is sample ID)\n",
    "    ind_genotypes = []\n",
    "    for geno in row[1:]:\n",
    "        if geno.strip() in new_coding_dict:  # Strip whitespace just in case\n",
    "            ind_genotypes.append(new_coding_dict[geno.strip()])\n",
    "        else:\n",
    "            # Handle missing or unexpected genotypes\n",
    "            ind_genotypes.append([0, 0])\n",
    "\n",
    "    out_dict['genotypes'].append(ind_genotypes)\n",
    "\n",
    "# Write to output file\n",
    "# import pickle as pk\n",
    "# pk.dump(out_dict, open(snakemake.output[0], 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out_dict['genotypes'][0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpatlas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
